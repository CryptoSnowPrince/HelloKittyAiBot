import aiogram
import asyncio
import config
import messages
import time
import urllib.request
import replicate
import os
from PIL import Image

os.environ['REPLICATE_API_TOKEN'] = config.REPLICATE_API_TOKEN
bot = aiogram.Bot(token=config.API_TOKEN,
                  parse_mode=aiogram.types.ParseMode.HTML)

loop = asyncio.get_event_loop()
dp = aiogram.Dispatcher(bot, loop=loop)
comps = {}

@dp.message_handler(commands=['help'])
async def help_message(message: aiogram.types.Message):
    await message.reply(messages.message['/help'])


@dp.message_handler(commands=['start'])
async def start_message(message: aiogram.types.Message):
    await message.reply(messages.message['/start'])


async def pending(message, username, origin_username):
    wait_t = int(time.time() - comps[username])
    wait_t = 40 - wait_t
    if wait_t > 0:
        countdown_m = await message.reply('@' + origin_username + ' You\'re in countdown mode please wait ' + str(wait_t) + ' seconds before using Kitty again.')


@dp.message_handler(lambda message: (message.text not in config.commands and message.text.startswith("/kitty ")))
async def handle_input(message: aiogram.types.Message):
    prompt = message.text.split("/kitty ")[1]
    if prompt.strip() == "":
        return

    print(message['from']['id'], message['chat']['username'],
          message['from']['username'], message.text)
    username = message['from']['username']
    origin_username = username if username else "none"
    if not username:
        username = str(time.time)

    if username in comps.keys() and (time.time() - comps[username]) < 40:
        await pending(message, username, origin_username)
        return
    comps[username] = time.time()
    model = replicate.models.get("tstramer/midjourney-diffusion")
    version = model.versions.get("436b051ebd8f68d23e83d22de5e198e0995357afef113768c20f0b6fcef23c8b") # https://replicate.com/tstramer/midjourney-diffusion/versions

    # https://replicate.com/tstramer/midjourney-diffusion/versions/436b051ebd8f68d23e83d22de5e198e0995357afef113768c20f0b6fcef23c8b#input
    inputs = {
        'prompt': "mdjrny-v4 style" + prompt + " , no same style object",

        # Specify things to not see in the output
        # 'negative_prompt': ...,

        # Width of output image. Maximum size is 1024x768 or 768x1024 because
        # of memory limits
        'width': 768,

        # Height of output image. Maximum size is 1024x768 or 768x1024 because
        # of memory limits
        'height': 768,

        # Prompt strength when using init image. 1.0 corresponds to full
        # destruction of information in init image
        'prompt_strength': 0.8,

        # Number of images to output.
        # Range: 1 to 4
        'num_outputs': 1,

        # Number of denoising steps
        # Range: 1 to 500
        'num_inference_steps': 50,

        # Scale for classifier-free guidance
        # Range: 1 to 20
        'guidance_scale': 7.5,

        # Choose a scheduler.
        'scheduler': "DPMSolverMultistep",

        # Random seed. Leave blank to randomize the seed
        # 'seed': ...,
    }
    wait_m = await message.reply(messages.message["/wait"])
    prediction = replicate.predictions.create(version=version, input=inputs)
    print("prediction thread")
    tm = 40
    output = []
    old_percent_m = ""
    while tm > 0:
        prediction.reload()
        print(prediction.status)
        if prediction.status == "failed":
            break
        print(prediction.logs)
        percent = 0
        if prediction.logs:
            percent = prediction.logs.split("\n")[-1].split("|")[0]

        percent_m = ""
        if percent:
            percent_m = percent
        print(prediction.status, origin_username, message.text, percent)
        if percent_m != old_percent_m:
            await wait_m.edit_text("Processing request from @" + origin_username + " | " + prompt + " | " + percent_m)
        old_percent_m = percent_m
        if prediction.status == 'succeeded':
            output = prediction.output
            break
        await asyncio.sleep(5)
        tm -= 5

    if len(output) == 0:
        await wait_m.edit_text("Try running it again, or try a different prompt")
        return
    generated_image_url = output[0]
    water_mark(generated_image_url, username)
    photo = open(f"images/{username}_watermarked.png", 'rb')
    await wait_m.delete()
    Telegram = "https://t.me/wonkatoken"
    Twitter = "https://HelloKittyETH.com"
    Website = "https://HelloKittyETH.com"
    BuyLink = "https://app.uniswap.org/#/swap?inputCurrency=ETH&outputCurrency=0x3e50a628F4aEe9A9A88a8d2B965a4A76Ffa79B50"
    caption = f"{prompt}\nimage generated by @{origin_username}\n\n <a href ='{Website}'>Website</a> | <a href ='{Telegram}'>Telegram</a> | <a href ='{BuyLink}'>Buy $KITTY</a>"
    await bot.send_photo(message.chat.id, photo, caption)
    photo.close()

def water_mark(image_url, username):
    urllib.request.urlretrieve(image_url, f"images/{username}.png")
    im = Image.open(f"images/{username}.png").convert("RGBA")
    water_mark = Image.open("watermark.png").convert("RGBA")
    alpha = water_mark.split()[-1]
    alpha = alpha.point(lambda p: int(float(p)/1.5))
    # print("\nalpha\n", alpha)
    water_mark.putalpha(alpha)
    water_mark_width, water_mark_height = water_mark.size
    width, height = im.size

    watermark_im = Image.new('RGBA', im.size, color=(0, 0, 0, 0))
    watermark_im.paste(
        water_mark, (width-water_mark_width, height-water_mark_height))

    watermark_im = Image.alpha_composite(im, watermark_im)

    watermark_im.save(f"images/{username}_watermarked.png")

if __name__ == "__main__":
    print("HelloKittyAiBot Started...")

    aiogram.executor.start_polling(dp, skip_updates=True)
